/**
 * Audio Demo Page
 * 
 * This page was generated by AI to demonstrate the audio system, the audio library, and the useAudio hooks.
 * Do NOT use code from this page unless you are absolutely sure it is correct and necessary.
 */

'use client';

import { useRef, useEffect, useState, useContext } from 'react';
import * as THREE from 'three';
import { Canvas, useFrame, useThree } from '@react-three/fiber';
import { OrbitControls } from '@react-three/drei';
import { AudioSessionContext, useParam, useCommit, useSpatial, useSpatialMode, usePreview } from '@/hooks/useAudio';
import { createAudioSession, GraphSpec } from '@/lib/audio';
import { Button } from '@/components/ui/button';
import { Separator } from '@/components/ui/separator';

// Initial audio graph spec
const initialSpec: GraphSpec = {
  version: '1.0.0',
  schema: 'graph@1',
  tempo: 120,
  seed: Date.now(),
  sampleRate: 48000,
  assets: [
    {
      id: 'sample1',
      kind: 'sample',
      src: '/audio/example1.flac', // Supports: .ogg, .mp3, .wav, .flac, .m4a
      loop: true,
    },
  ],
  nodes: [
    {
      id: 'player1',
      type: 'Player',
      assetId: 'sample1',
      params: { playbackRate: 1, loop: true, reverse: false },
    },
    {
      id: 'filter1',
      type: 'Filter',
      params: { frequency: 1000, Q: 1, type: 'lowpass' },
    },
    {
      id: 'reverb1',
      type: 'Reverb',
      params: { decay: 2, wet: 0.3 },
    },
    {
      id: 'gain1',
      type: 'Gain',
      params: { gain: 0.8 },
    },
  ],
  connections: [
    { from: { id: 'player1' }, to: { id: 'filter1' } },
    { from: { id: 'filter1' }, to: { id: 'reverb1' } },
    { from: { id: 'reverb1' }, to: { id: 'gain1' } },
  ],
  automations: [],
  buses: [],
  sends: [],
  mix: { masterGain: 0.9 },
  meta: {
    title: 'Audio Demo',
    author: 'Demo User',
    tags: ['demo', 'spatial'],
    createdAt: new Date().toISOString(),
  },
};

// Audio controls component
function AudioControls({ sharedContext }: { sharedContext: AudioContext | null }) {
  const session = useContext(AudioSessionContext);
  const [isPlaying, setIsPlaying] = useState(false);
  const [playbackRate, setPlaybackRate] = useParam('player1', 'playbackRate');
  const [frequency, setFrequency] = useParam('filter1', 'frequency');
  const [filterQ, setFilterQ] = useParam('filter1', 'Q');
  const [reverbWet, setReverbWet] = useParam('reverb1', 'wet');
  const [gain, setGain] = useParam('gain1', 'gain');
  const { commit, status, lastResult } = useCommit();
  const { mode, freeze, unfreeze } = useSpatialMode('gain1');
  const { enabled: previewEnabled, toggle: togglePreview } = usePreview('player1');
  const [renderDuration, setRenderDuration] = useState(30);

  const handleStartStop = () => {
    if (!session) return;
    const player = session.getNode('player1');
    if (!player) return;

    const rawPlayer = player.raw();
    
    console.log('[handleStartStop] Player state:', {
      isPlaying,
      state: rawPlayer.state,
      buffer: rawPlayer.buffer,
      bufferLoaded: rawPlayer.buffer?.loaded,
      bufferDuration: rawPlayer.buffer?.duration
    });
    
    if (isPlaying) {
      rawPlayer.stop();
      setIsPlaying(false);
      console.log('[handleStartStop] Stopped player');
    } else {
      try {
        console.log('[handleStartStop] Attempting to start player...');
        
        if (sharedContext && sharedContext.state === 'suspended') {
          console.log('[handleStartStop] Resuming suspended audio context...');
          sharedContext.resume().then(() => {
            console.log('[handleStartStop] Audio context resumed');
          });
        }
        
        
        rawPlayer.start("+0");
        setIsPlaying(true);
        console.log('[handleStartStop] Player started successfully');
      } catch (err) {
        console.error('[handleStartStop] Failed to start player:', err);
        alert('Failed to start audio. Check console for details.');
      }
    }
  };

  const handleFreeze = async () => {
    try {
      const result = await commit({
        normalize: false, // Preserve user's gain settings
        durationOverride: renderDuration
      });
      console.log('Committed:', {
        specHash: result.specHash,
        audioHash: result.audioHash,
        duration: result.duration,
      });

      // Freeze the spatial binding to use the rendered buffer
      freeze(result);
    } catch (err) {
      console.error('Freeze failed:', err);
      alert(`Render failed: ${err instanceof Error ? err.message : String(err)}`);
    }
  };

  const handleUnfreeze = () => {
    unfreeze();
  };

  return (
    <div className="w-80 bg-white dark:bg-gray-900 p-6 rounded-lg shadow-lg space-y-4">
      <h2 className="text-2xl font-bold mb-4">Audio Controls</h2>

      <div className="space-y-3">
        {/* Play/Stop Button */}
        <div className="p-3 bg-blue-50 dark:bg-blue-900 rounded">
          <Button
            onClick={handleStartStop}
            className="w-full"
            variant={isPlaying ? "destructive" : "default"}
          >
            {isPlaying ? '‚èπ Stop Spatial Audio' : '‚ñ∂ Start Spatial Audio'}
          </Button>
          <p className="text-xs mt-2 text-gray-600 dark:text-gray-400">
            {isPlaying ? 'Audio playing through 3D sphere' : 'Click to start playback through spatial audio'}
          </p>
        </div>

        <Separator />

        {/* Mode Status */}
        <div className={`p-3 rounded ${mode === 'live' ? 'bg-cyan-50 dark:bg-cyan-900' : 'bg-green-50 dark:bg-green-900'}`}>
          <p className="text-sm font-bold mb-1">
            {mode === 'live' ? 'üîµ Live Mode - Spatial Audio Active' : 'üü¢ Frozen Mode'}
          </p>
          <p className="text-xs text-gray-600 dark:text-gray-400">
            {mode === 'live' 
              ? 'Audio playing through 3D sphere in real-time. Adjust parameters below to hear changes!' 
              : 'Playing committed audio buffer through 3D sphere'}
          </p>
        </div>

        <Separator />

        {/* Spatial Audio Info */}
        <div className="p-3 bg-blue-50 dark:bg-blue-900 rounded">
          <p className="text-xs font-bold mb-1">üéß 3D Spatial Audio</p>
          <p className="text-xs text-gray-600 dark:text-gray-400">
            Audio flows: Player ‚Üí Filter ‚Üí Reverb ‚Üí Gain ‚Üí 3D Sphere
          </p>
          <p className="text-xs text-gray-600 dark:text-gray-400 mt-1">
            Move camera around to hear positional audio!
          </p>
        </div>

        <Separator />

        <div>
          <label className="block text-sm font-medium mb-1">
            Playback Rate: {playbackRate.toFixed(2)}
          </label>
          <input
            title="Playback Rate"
            type="range"
            min="0.25"
            max="4"
            step="0.01"
            value={playbackRate}
            onChange={(e) => setPlaybackRate(Number(e.target.value))}
            className="w-full"
          />
        </div>

        <Separator />

        <div>
          <label className="block text-sm font-medium mb-1">
            Filter Frequency: {frequency.toFixed(0)} Hz
          </label>
          <input
            title="Filter Frequency"
            type="range"
            min="20"
            max="20000"
            step="10"
            value={frequency}
            onChange={(e) => setFrequency(Number(e.target.value))}
            className="w-full"
          />
        </div>

        <div>
          <label className="block text-sm font-medium mb-1">
            Filter Q: {filterQ.toFixed(2)}
          </label>
          <input
            title="Filter Q"
            type="range"
            min="0.1"
            max="36"
            step="0.1"
            value={filterQ}
            onChange={(e) => setFilterQ(Number(e.target.value))}
            className="w-full"
          />
        </div>

        <Separator />

        <div>
          <label className="block text-sm font-medium mb-1">
            Reverb Wet: {(reverbWet * 100).toFixed(0)}%
          </label>
          <input
            title="Reverb Wet"
            type="range"
            min="0"
            max="1"
            step="0.01"
            value={reverbWet}
            onChange={(e) => setReverbWet(Number(e.target.value))}
            className="w-full"
          />
        </div>

        <Separator />

        <div>
          <label className="block text-sm font-medium mb-1">
            Gain: {(gain * 100).toFixed(0)}%
          </label>
          <input
            title="Gain"
            type="range"
            min="0"
            max="4"
            step="0.01"
            value={gain}
            onChange={(e) => setGain(Number(e.target.value))}
            className="w-full"
          />
        </div>

        <Separator />

        <div className="p-3 bg-green-50 dark:bg-green-900 rounded">
          {mode === 'live' ? (
            <>
              <Button
                onClick={handleFreeze}
                disabled={status === 'rendering'}
                className="w-full"
              >
                {status === 'rendering' ? 'Rendering...' : '‚ùÑÔ∏è Freeze (Optional)'}
              </Button>
              <p className="text-xs mt-2 text-gray-600 dark:text-gray-400">
                Optionally freeze current settings into a committed buffer. Not needed for real-time editing!
              </p>
            </>
          ) : (
            <>
              <Button
                onClick={handleUnfreeze}
                className="w-full"
                variant="outline"
              >
                üî• Unfreeze - Return to Live Mode
              </Button>
              <p className="text-xs mt-2 text-gray-600 dark:text-gray-400">
                Return to live mode for real-time parameter editing
              </p>
            </>
          )}
        </div>

        {lastResult && (
          <div className="mt-4 p-3 bg-gray-100 dark:bg-gray-800 rounded">
            <p className="text-xs font-bold text-green-600 dark:text-green-400 mb-2">
              ‚úì Spatial Audio Bound to Sphere
            </p>
            <p className="text-xs font-mono break-all">
              <strong>Spec Hash:</strong> {lastResult.specHash.substring(0, 16)}...
            </p>
            <p className="text-xs font-mono break-all">
              <strong>Audio Hash:</strong> {lastResult.audioHash.substring(0, 16)}...
            </p>
            <p className="text-xs">
              <strong>Duration:</strong> {lastResult.duration.toFixed(2)}s
            </p>
          </div>
        )}

        <div className="mt-4 p-3 bg-blue-50 dark:bg-blue-900 rounded text-xs">
          <p className="font-medium mb-1">üí° Dual-Path Architecture:</p>
          <ul className="list-disc list-inside space-y-1 text-xs">
            <li><strong>Live Path:</strong> Play button ‚Üí hear Tone.js effects instantly</li>
            <li><strong>Adjust:</strong> Sliders modify audio in real-time</li>
            <li><strong>Commit Path:</strong> Freeze ‚Üí render blob ‚Üí bind to 3D sphere</li>
            <li><strong>Spatial:</strong> Move camera to hear PositionalAudio effects</li>
          </ul>
        </div>
      </div>
    </div>
  );
}

// 3D Sound source sphere with spatial audio binding
function SoundSphere({ audioReady, sharedContext }: { audioReady: boolean; sharedContext: AudioContext | null }) {
  const meshRef = useRef<THREE.Mesh>(null);
  const { camera } = useThree();
  const listenerRef = useRef<THREE.AudioListener | null>(null);

  // Hooks handle null session gracefully
  const { mode } = useSpatialMode('gain1');

  useEffect(() => {
    // Add audio listener to camera using shared context
    if (camera && !listenerRef.current && sharedContext) {
      // Create AudioListener - THREE.js will create its own context
      const listener = new THREE.AudioListener();
      
      // This is expected - THREE.js creates its own context
      // Our MediaStream bridge will handle the connection
      if (listener.context !== sharedContext) {
        console.log('[SoundSphere] Using MediaStream bridge:', {
          toneContext: sharedContext.sampleRate + 'Hz',
          threeContext: listener.context.sampleRate + 'Hz',
          bridgeEnabled: true
        });
      }
      
      listenerRef.current = listener;
      camera.add(listener);

      console.log('‚úì AudioListener ready for spatial audio');
    }

    return () => {
      if (listenerRef.current && camera) {
        camera.remove(listenerRef.current);
      }
    };
  }, [camera, sharedContext]);

  // Bind spatial audio only when session is ready
  console.log('[SoundSphere] useSpatial deps:', { audioReady, meshRef: !!meshRef.current, listenerRef: !!listenerRef.current });
  
  useSpatial(
    'gain1', // Use the final node in the chain (player1 ‚Üí filter1 ‚Üí reverb1 ‚Üí gain1)
    meshRef as React.RefObject<THREE.Object3D>,
    listenerRef as React.RefObject<THREE.AudioListener>,
    {
      mode: 'live',
      refDistance: 5,
      rolloffFactor: 1,
      distanceModel: 'inverse',
    },
    [audioReady] // Re-bind when audio becomes ready
  );

  // Animate the sphere
  useFrame((state) => {
    if (meshRef.current) {
      meshRef.current.position.x = Math.sin(state.clock.elapsedTime * 0.5) * 3;
      meshRef.current.position.z = Math.cos(state.clock.elapsedTime * 0.5) * 3;
    }
  });

  // Color based on state: gray (loading) ‚Üí cyan (live) ‚Üí green (frozen)
  const color = !audioReady
    ? '#6b7280'  // gray - loading
    : mode === 'live'
      ? '#06b6d4'  // cyan - live
      : mode === 'committed'
        ? '#4ade80'  // green - frozen
        : '#6b7280'; // gray - unknown

  const emissiveIntensity = !audioReady ? 0.3 : mode === 'live' ? 0.6 : 0.5;

  return (
    <>
      <mesh ref={meshRef} position={[0, 0, 0]}>
        <sphereGeometry args={[0.5, 32, 32]} />
        <meshStandardMaterial
          color={color}
          emissive={color}
          emissiveIntensity={emissiveIntensity}
        />
      </mesh>
      <pointLight
        position={[0, 0, 0]}
        intensity={1}
        color={color}
      />
    </>
  );
}

// Main demo component
export default function AudioDemo() {
  const [session, setSession] = useState<any>(null);
  const [ready, setReady] = useState(false);
  const [error, setError] = useState<Error | null>(null);
  const [started, setStarted] = useState(false);
  const [loading, setLoading] = useState(false);
  const [sharedContext, setSharedContext] = useState<AudioContext | null>(null);

  const initAudio = async () => {
    if (loading || ready) return;

    setLoading(true);
    setStarted(true);

    try {
      // Create a shared AudioContext for both Tone.js and THREE.js
      const audioContext = new AudioContext();
      setSharedContext(audioContext);

      // Create audio session using the shared context
      const audioSession = await createAudioSession(initialSpec, { context: audioContext });
      setSession(audioSession);
      setReady(true);
      console.log('‚úì Audio session initialized with shared context');

      // The player will auto-start when the spatial binding connects
      // No need to manually start it here
      console.log('‚úì Audio session ready for spatial binding');

      // DO NOT connect to speakers - audio will only play through spatial binding
      // The spatial audio system will handle the output via PositionalAudio
    } catch (err) {
      console.error('Failed to create audio session:', err);
      setError(err instanceof Error ? err : new Error(String(err)));
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="flex h-screen w-screen bg-gray-100 dark:bg-gray-950">
      {!started ? (
        <div className="flex items-center justify-center w-full">
          <div className="text-center space-y-4">
            <h1 className="text-4xl font-bold">Audio System Demo</h1>
            <p className="text-gray-600 dark:text-gray-400 max-w-md">
              Demonstrating Tone.js ‚Üí Web Audio API ‚Üí Three.js PositionalAudio pipeline
            </p>
            <Button onClick={initAudio} size="lg" className="mt-4">
              Start Audio Demo
            </Button>
            <p className="text-xs text-gray-500 dark:text-gray-500 mt-4">
              Note: Place an audio file at <code className="bg-gray-200 dark:bg-gray-800 px-1 rounded">public/audio/example1.flac</code>
            </p>
          </div>
        </div>
      ) : (
        <AudioSessionContext.Provider value={session}>
          {/* Left panel - Controls */}
          <div className="flex-shrink-0 p-6 overflow-y-auto">
            {ready && session ? (
              <AudioControls sharedContext={sharedContext} />
            ) : (
              <div className="w-80 bg-white dark:bg-gray-900 p-6 rounded-lg shadow-lg">
                {error ? (
                  <div className="text-red-500">
                    <h3 className="font-bold mb-2">Error</h3>
                    <p className="text-sm">{error.message}</p>
                  </div>
                ) : (
                  <p>Loading audio session...</p>
                )}
              </div>
            )}
          </div>

          {/* Right panel - 3D Scene */}
          <div className="flex-1 relative">
            <Canvas camera={{ position: [0, 2, 8], fov: 50 }}>
              <color attach="background" args={['#1a1a1a']} />
              <ambientLight intensity={0.3} />
              <directionalLight position={[10, 10, 5]} intensity={1} />

              <SoundSphere audioReady={ready && !!session} sharedContext={sharedContext} />

              {/* Ground plane */}
              <mesh rotation={[-Math.PI / 2, 0, 0]} position={[0, -1, 0]} receiveShadow>
                <planeGeometry args={[20, 20]} />
                <meshStandardMaterial color="#2a2a2a" />
              </mesh>

              <gridHelper args={[20, 20, '#444', '#222']} position={[0, -0.99, 0]} />

              <OrbitControls makeDefault />
            </Canvas>

            <div className="absolute top-4 right-4 bg-white dark:bg-gray-900 p-4 rounded-lg shadow-lg text-sm max-w-xs">
              <h3 className="font-bold mb-2">3D Scene</h3>
              <p className="text-xs text-gray-600 dark:text-gray-400">
                {ready && session
                  ? 'üîµ Cyan/üü¢ Green sphere: Spatial audio active! Move camera to hear positional effects.'
                  : '‚ö´ Gray sphere: Waiting for audio system to start.'}
              </p>
              <p className="text-xs text-gray-600 dark:text-gray-400 mt-2">
                Use mouse to orbit, zoom, and pan the scene.
              </p>
            </div>
          </div>
        </AudioSessionContext.Provider>
      )}
    </div>
  );
}
